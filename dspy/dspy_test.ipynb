{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = dspy.LM(model = 'openai/gpt-4o-mini')\n",
    "\n",
    "dspy.settings.configure(lm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "dataset = HotPotQA(train_seed = 1, train_size = 20, eval_seed = 2023, dev_size = 50, test_size = 0)\n",
    "\n",
    "trainset, devset = dataset.train, dataset.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoTSignature(dspy.Signature):\n",
    "    \"\"\"Answer the question and give the reasoning for the same.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc = \"Question about something\")\n",
    "    answer = dspy.OutputField(desc = \"Often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoTPipeline(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.signature = CoTSignature\n",
    "        self.predictor = dspy.ChainOfThought(self.signature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        result = self.predictor(question = question)\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            answer = result.answer,\n",
    "            reasoning = result.reasoning,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    return answer_EM\n",
    "\n",
    "NUM_THREADS = 5\n",
    "evaluate = Evaluate(devset=devset, metric=validate_context_and_answer, num_threads=NUM_THREADS, display_progress=True, display_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 50  (24.0):  98%|█████████▊| 49/50 [00:00<00:00, 1419.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 50  (24.0): 100%|██████████| 50/50 [00:00<00:00, 1426.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_baseline = CoTPipeline()\n",
    "\n",
    "devset_with_input = [dspy.Example({\"question\": r[\"question\"], \"answer\": r[\"answer\"]}).with_inputs(\"question\") for r in devset]\n",
    "trainset_with_input = [dspy.Example({\"question\": r[\"question\"], \"answer\": r[\"answer\"]}).with_inputs(\"question\") for r in trainset]\n",
    "evaluate(cot_baseline, devset=devset_with_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import COPRO\n",
    "\n",
    "optimizer = COPRO(\n",
    "    metric = validate_context_and_answer,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 11.52it/s]\n",
      "Average Metric: 6 / 20  (30.0): 100%|██████████| 20/20 [00:01<00:00, 11.46it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:02<00:00,  8.22it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 10.84it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 13.59it/s]\n",
      "Average Metric: 9 / 20  (45.0): 100%|██████████| 20/20 [00:02<00:00,  9.50it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 10.11it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 11.97it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:04<00:00,  4.87it/s]\n",
      "Average Metric: 6 / 20  (30.0): 100%|██████████| 20/20 [00:02<00:00,  6.78it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 11.70it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 11.04it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 12.14it/s]\n",
      "Average Metric: 6 / 20  (30.0): 100%|██████████| 20/20 [00:02<00:00,  9.81it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 10.71it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 12.81it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:02<00:00,  8.04it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:02<00:00,  6.81it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:03<00:00,  5.86it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:03<00:00,  6.16it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 10.13it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:02<00:00,  9.32it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:02<00:00,  9.84it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:01<00:00, 10.98it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:02<00:00,  7.23it/s]\n",
      "Average Metric: 8 / 20  (40.0): 100%|██████████| 20/20 [00:03<00:00,  5.12it/s]\n",
      "Average Metric: 6 / 20  (30.0): 100%|██████████| 20/20 [00:02<00:00,  7.46it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:05<00:00,  3.91it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:01<00:00, 11.30it/s]\n",
      "Average Metric: 7 / 20  (35.0): 100%|██████████| 20/20 [00:02<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(num_threads=64, display_progress=True, display_table=0) # Used in Evaluate class in the optimization process\n",
    "\n",
    "compiled_prompt_opt = optimizer.compile(CoTPipeline(), trainset=trainset_with_input, eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_predictors of predictor = Predict(StringSignature(question -> reasoning, answer\n",
       "    instructions='Answer the question and give the reasoning for the same.'\n",
       "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Question about something', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
       "))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_prompt_opt.named_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
