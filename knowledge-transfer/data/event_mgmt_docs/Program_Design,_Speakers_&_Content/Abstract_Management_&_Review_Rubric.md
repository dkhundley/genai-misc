# Abstract Management & Review Rubric
Program Design, Speakers & Content

Document Title: Abstract Management & Review Rubric  
Document Description: Specifies submission fields, scoring criteria, committee workflow, and acceptance communications. Format: submission form schema, rubric, and reviewer portal guide.

---------------------------------------

## Overview

This document defines the end-to-end process for managing session abstracts for the [Annual Summit] program, including the submission form schema, review rubric, committee workflow, and acceptance communications. It is designed so that a team member with no prior context can execute the process from call launch to final scheduling.

Key goals:
- Gather high-quality, diverse, practical, and non-commercial content aligned with event tracks.
- Provide fair, timely, and bias-aware peer review at scale.
- Communicate clear decisions and next steps to submitters and speakers.

Event context (example):
- Event: Annual Summit 2026
- Dates: October 6–8, 2026 (in-person), virtual encore October 20–21, 2026
- Audience: 2,000+ professionals (practitioners, leaders, technical experts)
- Session types: Keynote (60), Breakout (45/60), Workshop (90/120), Panel (60), Lightning Talk (15), Poster (expo)
- Tracks (example): Strategy & Leadership; Data & AI; Product & UX; Engineering & Architecture; Operations & Security; People & Culture; Customer Success & GTM

Target acceptance rate: 28–35% total (varies by track and type)

---------------------------------------

## Timeline (Example for 2026 Program Cycle)

- Jan 13: CFP opens (12:00 PT)
- Feb 28: CFP closes (23:59 PT)
- Mar 1–3: Admin triage, anonymization checks, COI pre-screen
- Mar 4–17: Round 1 review (blind), 3 reviewers/abstract
- Mar 18–21: Calibration & discussion period
- Mar 24–28: Round 2 curation (merge/reshape, balance tracks)
- Apr 1–5: Program committee selection meeting; conditional accepts confirmed
- Apr 8–10: Decision letters sent (accept/conditional/waitlist/decline)
- Apr 22: Speaker confirmation deadline
- May 6: Final session titles/abstracts due (public site copy)
- June 3: Slide template & accessibility guidelines released
- Aug 5: Draft slides due; speaker tech checks scheduled
- Sept 9: Final slides due for review/brand check
- Oct 6–8: Event delivery
- Oct 27: Post-event content cleanup and speaker surveys
- Nov 10: Debrief; reviewer recognition; data archive

---------------------------------------

## Roles & Responsibilities

- Program Chair: Owns rubric, ensures fairness, chairs selection meeting, signs off on final slate.
- Track Leads (1–2 per track): Assign reviewers, moderate discussions, propose merges/reshapes, manage conditional feedback.
- Abstracts Subcommittee: Designs CFP, fields submitter questions, ensures DEI and accessibility goals, monitors progress.
- Reviewers (SMEs): Score abstracts against rubric, provide constructive feedback, disclose COI, participate in calibration.
- Content Operations: Manages submission system, templates, deadlines, speaker onboarding, data exports, and schedule build.
- Communications Lead: Sends decision letters, manages Q&A, updates website copy.
- Legal/Compliance: Reviews speaker agreement, COI, and promotional policies.

---------------------------------------

## Submission Form Schema

Use this schema in your submission platform (e.g., OpenWater, Oxford Abstracts, Ex Ordo, Airtable + forms). All “Required” fields are enforced; apply word/character limits and validation as specified.

A. Submitter Information
- Submitter Full Name (Required, Text)
- Email (Required, Email; unique)
- Organization (Required, Text)
- Country/Time Zone (Required, Dropdown)
- Role/Seniority (Required, Dropdown: Individual Contributor, Manager, Director, VP, C-level, Consultant, Academic, Student)
- Consent: Contact for updates (Required, Checkbox)
- Consent: Data processing & privacy policy (Required, Checkbox, link to policy)

B. Session Details
- Session Title (Required, Text, 10–90 characters; no title case requirement; no emojis)
- Abstract (Required, Long text, 100–150 words; max 180; anonymized—no company/product names)
- Session Type (Required, Dropdown: Breakout 45, Breakout 60, Workshop 90, Workshop 120, Panel 60, Lightning 15, Poster)
- Track (Required, Dropdown from event tracks)
- Audience Level (Required, Dropdown: Beginner, Intermediate, Advanced)
- Learning Objectives (Required, 3 items, each 10–25 words; start with action verbs)
- Primary Topic Keywords (Required, Multi-select up to 5)
- Practical Takeaways (Required, Short bullets, 3–5 items)
- Interactivity Plan (Required, 50–150 words; e.g., polls, case exercises, Q&A structure)
- Accessibility Plan (Required, 30–100 words; e.g., describe visuals, readable slides, microphone discipline)
- DEI/Representation Plan (Required, 30–100 words; speaker demographics sensitivity; inclusive examples)
- Problem Statement & Relevance (Required, 50–120 words)
- Evidence/Method (Conditional; Required for case studies/research: 50–150 words; cite sources or data)
- Prior Presentation History (Required, Yes/No; if yes: where/when; what’s new for this audience?)
- Expected Outcomes/Measurement (Optional, 30–100 words)
- Proposed Duration Fit (Required, Dropdown; confirm fit to selected type)
- Scheduling Constraints (Optional, free text; not guaranteed)

C. Speaker(s)
- Presenter Count (Required, 1–4 limit; panels up to 5 incl. moderator)
- For each presenter:
  - Full Name (Required)
  - Pronouns (Optional)
  - Title & Organization (Required)
  - Email (Required)
  - Short Bio (Required, 40–80 words; avoid company/product promotion)
  - Headshot (Required, JPG/PNG, min 800x800)
  - City/Country (Required)
  - Prior Speaking Links (Optional, up to 2 URLs)
  - Accessibility Needs (Optional)
  - Conflict of Interest (Required, Yes/No; if Yes: describe relationship)
  - Commercial Affiliation (Required: Is presentation connected to a product/service you sell? Yes/No)
  - Consent: Speaker Agreement (Required, Checkbox; link provided)

D. Logistics & AV
- AV Needs (Required, Multi-select: HDMI, audio out, microphones, whiteboard, flipcharts, round tables)
- Materials Upload (Optional: draft slides, outline, workbook, PDF only, max 10MB)
- Recording Consent (Required, Yes/No)
- Photo Consent (Required, Yes/No)
- Marketing Snippet (Required, 30–50 words; web listing copy; non-anonymized)
- Alternate Format Willingness (Optional, Multi-select: convert to panel, lightning, workshop)
- Travel Support Request (Optional; for community/nonprofit/student—subject to approval)

Validation/Anonymization
- Review-stage copy hides speaker names/orgs and marketing snippet.
- System auto-flags company/product names in abstract via keyword list for admin review.
- Incomplete or non-compliant entries are returned once for correction (48-hour grace within CFP window).

Example Entry Snippet
- Title: Cut Incidents by 40%: A Playbook for On-Call Health
- Abstract: Many teams struggle with alert fatigue and burnout. This session shares data from a 14-team rollout of on-call health metrics, including incident volume, MTTR, and staffing rotations. Attendees leave with a step-by-step maturity model and templates to implement in under 90 days.
- Learning Objectives:
  1) Define four measurable on-call health indicators and set baseline targets.
  2) Apply a 3-phase rollout plan with stakeholder mapping.
  3) Evaluate outcomes and adjust runbooks using weekly reviews.

---------------------------------------

## Scoring Rubric

Scoring Scale (1–5)
- 1 = Poor
- 2 = Fair
- 3 = Good
- 4 = Very Good
- 5 = Excellent

Weights (Total 100)
- Relevance to Track/Audience (15)
- Problem Clarity & Importance (10)
- Originality/Novelty (10)
- Practicality & Applicability (15)
- Learning Objectives Quality (10)
- Evidence/Methodological Rigor (10)
- Speaker Expertise & Credibility (10)
- Interactivity & Engagement Plan (8)
- DEI & Inclusive Design (5)
- Non-Commercial Nature (5)
- Feasibility Within Time/Format (7)
- Writing Clarity/Quality (5)

Criterion Guidance (examples)
- Relevance (15): 1 = off-topic; 3 = relevant to sub-cohort; 5 = highly aligned with track goals and attendee needs.
- Problem Clarity (10): 1 = vague; 3 = understandable; 5 = clear, compelling need with context.
- Originality (10): 1 = common/overdone; 3 = incremental improvement; 5 = new perspective, data, or technique.
- Practicality (15): 1 = vague advice; 3 = some actionable steps; 5 = concrete tools, templates, steps, and metrics.
- Learning Objectives (10): 1 = not measurable; 3 = partially measurable; 5 = specific, measurable, and aligned.
- Evidence/Rigor (10): 1 = anecdotes only; 3 = some data/citations; 5 = robust data/method with limits stated.
- Expertise (10): 1 = limited; 3 = moderate evidence; 5 = strong track record, credible references.
- Interactivity (8): 1 = lecture-only; 3 = Q&A only; 5 = planned engagement at 10–15 min intervals.
- DEI & Inclusion (5): 1 = not addressed; 3 = basic awareness; 5 = meaningful inclusion in content/examples/speakers.
- Non-Commercial (5): 1 = overt pitch; 3 = some vendor bias; 5 = vendor-neutral, value-first.
- Feasibility (7): 1 = unrealistic; 3 = tight; 5 = appropriately scoped and timed.
- Writing Quality (5): 1 = unclear/errors; 3 = readable; 5 = crisp, compelling, error-free.

Overall Recommendation (choose one)
- Strong Accept, Accept, Borderline, Reject
- Confidence Level: Low/Medium/High

Auto-Flags/Disqualifiers
- Direct product demo or sales pitch (unless session type allows; still scored low on non-commercial).
- Plagiarism or previously presented talk with no meaningful updates.
- COI not disclosed or unverifiable claims.
- Incomplete learning objectives.

Thresholds & Selection Rules
- Average weighted score ≥ 3.8 typically accepted unless space constraints.
- 3.5–3.79 considered if it helps track balance, diversity, and topic coverage.
- ≤ 3.49 typically declined unless strategic fit with conditional revisions.
- At least 3 independent reviews per abstract; remove highest/lowest in case of >4 reviews if variance ≥ 1.5.

---------------------------------------

## Committee Workflow

1) CFP Prep (2–3 weeks before launch)
- Finalize tracks, session types, rubric, and submission schema.
- Load form into platform; test for validation and anonymization.
- Publish CFP page: dates, scope, tips, FAQs, code of conduct, and policies.
- Recruit reviewers (3–5 per track). Target load: 20–30 abstracts/reviewer.

2) Call Launch
- Promote via email, social, community channels. Provide office hours.
- Monitor submissions daily for policy compliance. Return for correction where needed.

3) Triage & COI Pre-Screen (post-close)
- Remove PII from reviewer-facing copy (auto + manual spot checks).
- Auto-flag overlaps: same submitter multiple entries, excessive vendor keywords.
- COI tagging: reviewers declare organizations/clients; system avoids assignments accordingly.

4) Assignment
- Each abstract gets 3 reviewers from the relevant track (or adjacent track if niche).
- Balance workload and ensure expertise alignment; allow self-assign pool for unfilled topics.

5) Reviewer Training & Calibration
- 30-minute webinar or recorded video covering rubric, examples, and bias mitigation.
- Provide 3 sample abstracts for practice; collect scores; publish anchor results.

6) Round 1 Blind Review (two weeks)
- Reviewers score and comment independently. Required: at least one public comment for submitter feedback and one private note for committee.

7) Discussion & Reconciliation (3–4 days)
- Track Leads open discussion threads for high-variance abstracts or top contenders.
- Encourage merges (e.g., combine two similar lightning talks into a panel).
- Adjustments only with documented rationale; maintain audit trail.

8) Round 2 Curation & Program Build
- Apply selection thresholds; ensure track balance, diversity, speaker mix (avoid single-org dominance).
- Design conditional accept notes (e.g., clarify objectives, remove brand terms, add hands-on segment).
- Identify waitlist priorities and alternates for each time slot.

9) Selection Meeting (Program Committee)
- Review slate by track and session type; finalize accepts, conditionals, waitlists.
- Approve keynote shortlists separately if applicable.

10) Decision Communications (3-day window)
- Send accept/conditional/waitlist/decline letters with clear deadlines and next steps.
- Update internal tracker with statuses; open speaker portal for accepted sessions.

11) Speaker Confirmation & Onboarding
- Collect speaker agreements, bios, headshots, AV needs; confirm session time windows.
- Schedule orientation: content guidelines, accessibility, anti-harassment policy.
- Assign session owner (Track Lead) for content QA.

12) Pre-Event Content QA
- Review draft slides for clarity, branding, accessibility. Provide feedback 3–4 weeks out.
- Tech checks scheduled 2–3 weeks out; confirm recording preferences.

13) Post-Event
- Send speaker and reviewer thank-yous and surveys.
- Archive data; compile lessons learned.

Bias Mitigation Practices
- Double-blind abstract review (authors hidden; reviewers known to Track Lead).
- Standardized rubric and calibration.
- DEI goals: target at least 40% underrepresented speaker representation across the program.
- Single-organization cap: no more than 3 accepted sessions per company per track (exceptions require Chair approval).

Data & Audit
- Keep all scores, comments, and decisions with timestamps.
- Export CSV for analysis (variance, acceptance by track, diversity metrics).
- Retain identifiable submission data for 24 months; anonymized scores indefinitely for benchmarking.

---------------------------------------

## Reviewer Portal Guide

Access
- Login: SSO or email/password via submission platform.
- Dashboard shows: Assigned abstracts, due dates, status filters, messages.

How to Review
- Open abstract; read Title, Abstract, Objectives, Interactivity, Track, Level, and anonymized content.
- Check COI: If any conflict, click “Recuse” and note reason.
- Score each criterion (1–5). The system calculates weighted score.
- Provide comments:
  - Private to committee: candid notes, potential merges, concerns.
  - Public to submitter: constructive, respectful, specific suggestions (no identity-revealing info).
- Overall Recommendation: Strong Accept/Accept/Borderline/Reject + Confidence.
- Flagging: Use “Commercial Bias,” “Out of Scope,” or “Policy Concern” tags as needed.
- Save and submit. You can edit before the Round 1 deadline.

Etiquette & Quality
- Anchor to rubric definitions; avoid preferences unrelated to value or audience fit.
- Provide at least 2–3 actionable suggestions in public comments for non-accepted submissions.
- Avoid guessing the author; judge on content.
- Aim to complete 50% of assigned reviews in week 1 to allow discussions in week 2.

Discussion
- During reconciliation, participate in comment threads for high-variance abstracts.
- Argue from rubric and attendee value; disclose any new context.

Deadlines
- Round 1 reviews due: Mar 17, 23:59 PT.
- Discussion wraps: Mar 21.

Support
- Contact: program@yourorg.org or #abstract-review Slack channel.
- Troubleshooting: Clear cache, try incognito, or use Chrome/Edge latest versions.

---------------------------------------

## Acceptance Communications

General Notes
- Send from program@yourorg.org with reply-to monitored.
- Use personalized merge fields (submitter name, session title, track).
- Include deadlines and consequences for missed deadlines (e.g., automatic withdrawal).

1) Acceptance Email (Unconditional)
Subject: Your session is accepted for Annual Summit 2026

Hello [First Name],

Congratulations! Your proposal, “[Session Title],” has been accepted for the [Track] track at Annual Summit 2026.

Key details:
- Provisional slot: [Date], [Time Zone], [Duration], [Room/Format]
- Speaker benefits: [Comp pass/discount], speaker lounge access, session recording (opt-in)
- Next steps:
  1) Confirm participation by [Apr 22] via the Speaker Portal: [portal link]
  2) Review and sign the Speaker Agreement: [link]
  3) Submit final title/abstract and speaker bios by [May 6]
  4) Attend speaker orientation on [date/time]: [calendar link]

Resources:
- Content & Accessibility Guidelines: [link]
- Slide Template: [link]
- Code of Conduct: [link]

We’re thrilled to feature your session. Thank you!

Best,  
[Program Chair Name]  
Program Team, Annual Summit

2) Conditional Acceptance Email
Subject: Conditional acceptance: “[Session Title]” — action required by [date]

Hello [First Name],

Your proposal, “[Session Title],” is conditionally accepted pending the updates below:
- Clarify learning objectives to be measurable.
- Remove brand/product references from the abstract.
- Add a 10-minute audience exercise (outline provided).

Please submit revisions in the Speaker Portal by [Apr 22]. Once approved, we’ll confirm scheduling.

If revisions are not received by the deadline, we may move the session to waitlist status.

Thank you!  
[Track Lead Name] | [Program Chair Name]

3) Waitlist Email
Subject: Waitlist status: “[Session Title]”

Hello [First Name],

Thank you for your strong submission. “[Session Title]” is on our waitlist due to limited space. Your position: [e.g., 2nd for Track]. If a slot opens or a session converts to a panel/lightning, we may reach out by [May 20].

You may optionally opt into a virtual encore session on Oct 20–21. Please indicate your interest here: [form link].

We appreciate your contribution and hope to include you.

Best,  
Program Team

4) Decline Email (with Feedback)
Subject: Decision for “[Session Title]”

Hello [First Name],

Thank you for submitting to Annual Summit 2026. After a competitive review process, we’re not able to include “[Session Title]” this year.

Reviewer feedback highlights:
- Strengths: [auto-merge public comments]
- Suggestions: [auto-merge public comments]

We encourage you to resubmit next year. Our CFP tips are here: [link].

With appreciation,  
Program Team

5) Speaker Reminder/Withdrawal Notice
Subject: Action required: confirm by [date] or we’ll release your slot

Hello [First Name],  
Friendly reminder to confirm participation and complete your Speaker Agreement by [date]. If we don’t hear from you, we’ll move your session to the waitlist and reassign your slot.

Reply with any questions.

---------------------------------------

## Key Steps Summary

- Configure the form using the schema and publish the CFP page.
- Recruit and onboard reviewers; deliver rubric training.
- Enforce anonymized review and COI policies.
- Run Round 1 scoring and Round 2 curation; document decisions.
- Send decision letters with clear deliverables and deadlines.
- Onboard accepted speakers; run content QA and tech checks.
- Archive results and debrief.

---------------------------------------

## Dependencies

Systems & Tools
- Submission Platform: [OpenWater/Ex Ordo/Oxford Abstracts/Airtable]
- Reviewer SSO: [Okta/Azure AD]
- Communications: [Mailgun/SendGrid], templates managed in [HubSpot/Marketo]
- Collaboration: Slack channel #abstract-review; Google Drive for shared docs
- Schedule Build: [Sched/Zerista/Cvent Attendee Hub]
- Recording/AV: [Vendor], needs matrix integrated with Speaker Portal

Policies & Legal
- Code of Conduct and Anti-Harassment Policy
- Privacy Policy (GDPR/CCPA compliance)
- Speaker Agreement (recording rights, ownership, consent)
- COI & Commercial Policy (no pay-to-play; balanced representation)
- Accessibility Standards (WCAG 2.1 AA for materials; on-site accommodation process)

People & Capacity
- Minimum 60 active reviewers for 600 submissions (load ≈ 25 each)
- Track Leads: 8–12 total depending on number of tracks
- Comms SLA: response to submitter questions within 2 business days

---------------------------------------

## References or Templates

Links to Internal Resources (replace with actual links)
- CFP Web Copy Template (includes scope, tips, FAQs)
- Reviewer Training Deck and Sample Abstracts
- Speaker Agreement Template
- Content & Accessibility Guidelines (font sizes, contrast, alt-text, mic use)
- Slide Template (16:9, brand-compliant)
- Decision Email Templates (above)
- Program Tracker (Google Sheet): status, scores, decisions, comms log

CFP Page Snippet (Website Copy)
- Headline: Share your expertise at Annual Summit 2026
- Dates: CFP opens Jan 13; closes Feb 28 (23:59 PT)
- What we seek: practical, original, inclusive sessions aligned to our tracks.
- Review process: double-blind abstract review; 3 reviewers per submission; DEI and non-commercial policies enforced.
- Speaker benefits: [comp passes/discounts], recording, professional photos.
- Submission tips: write measurable objectives; show evidence; plan interaction every 10–15 minutes; avoid product pitches.
- Accessibility & Inclusion: We welcome diverse speakers. Travel grants available for community contributors.

Reviewer Comment Prompts (to improve quality)
- What specific new insight or technique does this session offer?
- How actionable are the takeaways for our audience within 30–90 days?
- What revisions would materially improve clarity or value?
- Any risks (bias, feasibility, scope) and how to mitigate?

Post-Selection Schedule Build Checklist
- Confirm duration and format
- Avoid speaker double-booking
- Balance topics per time block and room size
- Tag sessions for filters (track, level, format, keywords)
- Publish preview titles; lock changes one week before public release

---------------------------------------

## Metrics & Reporting

Track and report:
- Submissions per track/type; acceptance rate; diversity metrics
- Average and variance of scores; reviewer reliability (intra-class correlation)
- Time-to-decision; % on-time reviewer completion
- Audience satisfaction post-event (NPS by session); correlation with rubric scores
- Commercial bias flags and outcomes

Set improvement targets (example):
- Reduce score variance >1.5 by 20% YoY via calibration.
- Increase representation of first-time speakers to 35%.
- Achieve ≥ 4.3/5 average attendee rating for accepted sessions.

---------------------------------------

This document should be used as the single source of truth for abstract management and review for the Annual Summit program cycle. Adjust dates, tools, and benefits to fit your organization.