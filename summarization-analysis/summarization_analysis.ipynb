{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization Metrics\n",
    "\n",
    "In this notebook, we will demonstrate how to calculate metrics to assess the quality of a Generative AI (GenAI) summary. Unfortunately, there isn't a particularly clean way for analyzing any GenAI model, as the quality of the summary is subjective. However, we can use some metrics to get a sense of how well the model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the LangChain chat model\n",
    "chat_model = ChatOpenAI(api_key = os.getenv('PERPLEXITY_API_KEY'),\n",
    "                        base_url = 'https://api.perplexity.ai',\n",
    "                        model = 'llama-3.1-70b-instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation\n",
    "In order to proceed forward with this notebook, we'll need to simulate some fake data. For your benefit, I have saved the simulated data back as a CSV back to this repo so that you don't have to regenerate the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt to generate topics around various IT related activities\n",
    "TOPIC_GENERATION_PROMPT = '''Assume that you are an IT helpdesk specialist that is responsible for providing technical support to users. Please generate a list of 10 different topics that you might help users with. Please output the final response as a JSON list. Only include the JSON list with no additional text. Follow the example below:\n",
    "\n",
    "Example:\n",
    "[\"Resetting a Password\", \"Setting Up a VPN\"]\n",
    "'''\n",
    "\n",
    "# Setting the prompt template to generate the IT related topics\n",
    "topic_generation_template = ChatPromptTemplate(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = TOPIC_GENERATION_PROMPT)\n",
    "])\n",
    "\n",
    "# Creating a chain to generate the IT related topics\n",
    "topic_generation_chain = topic_generation_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Troubleshooting Printer Connectivity Issues', 'Configuring Email on a Mobile Device', 'Resetting a Forgotten Password', 'Installing and Updating Software', 'Resolving Wi-Fi Connectivity Problems', 'Setting Up a New Computer or Laptop', 'Configuring Dual Monitors', 'Troubleshooting Microsoft Office Issues', 'Setting Up a Virtual Private Network (VPN)', 'Backing Up and Restoring Data']\n"
     ]
    }
   ],
   "source": [
    "# Checking if the simulated data file exists and generating topics if it does not\n",
    "if not os.path.exists('simulated_data.csv'):\n",
    "\n",
    "    # Generating topics using the topic generation chain\n",
    "    generated_topics = json.loads(topic_generation_chain.invoke(input = {}))\n",
    "    print(generated_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt to simulate a conversation between an IT helpdesk specialist and a user\n",
    "CONVERSATION_SIMULATION_PROMPT = '''Assume you are an IT helpdesk specialist responsible for providing technical support to users. You’ve received a call from a user experiencing trouble with their computer. Simulate a natural conversation between you and the user, addressing the issue in a friendly, professional, and helpful manner. \n",
    "\n",
    "- Ensure the conversation contains at least 10 back-and-forth exchanges.\n",
    "- The user may provide vague or incomplete information initially; ask for clarifications when necessary.\n",
    "- Include at least three troubleshooting steps in the conversation.\n",
    "- If the issue can’t be resolved on the call, suggest escalation or other solutions.\n",
    "- Keep the user engaged, acknowledging frustrations or confusion as needed, while explaining solutions clearly.\n",
    "\n",
    "Here is the topic:\n",
    "{topic}\n",
    "\n",
    "Please format the output as a list of messages in the following JSON format:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": \"Hello, I am having trouble with my computer.\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"specialist\",\n",
    "        \"message\": \"I'm sorry to hear that! Could you please describe the issue in more detail?\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "\n",
    "# Setting the prompt template to simulate the conversations\n",
    "conversation_generation_template = ChatPromptTemplate(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = CONVERSATION_SIMULATION_PROMPT)\n",
    "])\n",
    "\n",
    "# Creating the conversation simulation chain\n",
    "conversation_generation_chain = conversation_generation_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a Pandas DataFrame with a single column called 'original_text'\n",
    "df = pd.DataFrame(columns = ['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
