{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization Metrics\n",
    "\n",
    "In this notebook, we will demonstrate how to calculate metrics to assess the quality of a Generative AI (GenAI) summary. Unfortunately, there isn't a particularly clean way for analyzing any GenAI model, as the quality of the summary is subjective. However, we can use some metrics to get a sense of how well the model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the LangChain chat model\n",
    "chat_model = ChatOpenAI(api_key = os.getenv('PERPLEXITY_API_KEY'),\n",
    "                        base_url = 'https://api.perplexity.ai',\n",
    "                        model = 'llama-3.1-70b-instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation\n",
    "In order to proceed forward with this notebook, we'll need to simulate some fake data. For your benefit, I have saved the simulated data back as a CSV back to this repo so that you don't have to regenerate the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt to generate topics around various IT related activities\n",
    "TOPIC_GENERATION_PROMPT = '''Assume that you are an IT helpdesk specialist that is responsible for providing technical support to users. Please generate a list of 10 different topics that you might help users with. Please output the final response as a JSON list. Only include the JSON list with no additional text. Follow the example below:\n",
    "\n",
    "Example:\n",
    "[\"Resetting a Password\", \"Setting Up a VPN\"]\n",
    "'''\n",
    "\n",
    "# Setting the prompt template to generate the IT related topics\n",
    "topic_generation_template = ChatPromptTemplate(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = TOPIC_GENERATION_PROMPT)\n",
    "])\n",
    "\n",
    "# Creating a chain to generate the IT related topics\n",
    "topic_generation_chain = topic_generation_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resetting a Password', 'Setting Up a VPN', 'Troubleshooting Wi-Fi Connectivity Issues', 'Configuring Email Clients', 'Installing Software Updates', 'Resolving Printer Connection Problems', 'Configuring Two-Factor Authentication', 'Troubleshooting Microsoft Office Issues', 'Setting Up a New Laptop or Desktop Computer', 'Restoring Access to a Locked-Out Account']\n"
     ]
    }
   ],
   "source": [
    "# Checking if the simulated data file exists\n",
    "if not os.path.exists('simulated_data.csv'):\n",
    "\n",
    "    # Generating topics using the topic generation chain\n",
    "    generated_topics = json.loads(topic_generation_chain.invoke(input = {}))\n",
    "    print(generated_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt to simulate a conversation between an IT helpdesk specialist and a user\n",
    "CONVERSATION_SIMULATION_PROMPT = '''Assume you are an IT helpdesk specialist responsible for providing technical support to users. You’ve received a call from a user experiencing trouble with their computer. Simulate a natural conversation between you and the user, addressing the issue in a friendly, professional, and helpful manner. \n",
    "\n",
    "- Ensure the conversation contains at least 10 back-and-forth exchanges.\n",
    "- The user may provide vague or incomplete information initially; ask for clarifications when necessary.\n",
    "- Include at least three troubleshooting steps in the conversation.\n",
    "- If the issue can’t be resolved on the call, suggest escalation or other solutions.\n",
    "- Keep the user engaged, acknowledging frustrations or confusion as needed, while explaining solutions clearly.\n",
    "\n",
    "Here is the topic:\n",
    "{topic}\n",
    "\n",
    "Please format the output as a list of messages in the following JSON format. Do not include any additional text except for this JSON format. Do not say anything like \"Here is the simulated conversation.\" Follow the example below:\n",
    "\n",
    "[\n",
    "    {{\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": \"Hello, I am having trouble with my computer.\"\n",
    "    \\}},\n",
    "    {{\n",
    "        \"sender\": \"specialist\",\n",
    "        \"message\": \"I'm sorry to hear that! Could you please describe the issue in more detail?\"\n",
    "    \\}}\n",
    "]\n",
    "'''\n",
    "\n",
    "# Setting the prompt template to simulate the conversations\n",
    "conversation_generation_template = ChatPromptTemplate(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = CONVERSATION_SIMULATION_PROMPT)\n",
    "])\n",
    "\n",
    "# Creating the conversation simulation chain\n",
    "conversation_generation_chain = conversation_generation_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the simulated data file exists\n",
    "if not os.path.exists('simulated_data.csv'):\n",
    "\n",
    "    # Instantiating a Pandas DataFrame with a single column called 'original_text'\n",
    "    df = pd.DataFrame(columns = ['original_text'])\n",
    "\n",
    "    # Iterating through the generated topics\n",
    "    for topic in generated_topics:\n",
    "\n",
    "        # Generating the conversation based on the current topic\n",
    "        conversation = conversation_generation_chain.invoke(input = {'topic': topic})\n",
    "\n",
    "        # Appending the conversation to the DataFrame using pd.concat\n",
    "        df = pd.concat([df, pd.DataFrame({'original_text': [conversation]})], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a generic prompt that summarizes a body of text\n",
    "GENERIC_SUMMARIZATION_PROMPT = '''Please provide a concise summary of the following original text in a single paragraph. Your summary should:\n",
    "\n",
    "- Capture the main ideas and key points of the original text\n",
    "- Be approximately 100-150 words in length\n",
    "- Maintain the original tone and style of the text\n",
    "- Include any crucial details, facts, or figures\n",
    "- Avoid adding any new information not present in the original text\n",
    "- Use clear and coherent language\n",
    "- Synthesize the main ideas into a cohesive paragraph that accurately represents the essence of the original text.\n",
    "\n",
    "When providing the summary, please do not include any additional text or formatting. Do not say anything like \"Here is the summary.\"\n",
    "\n",
    "Original text:\n",
    "{original_text}\n",
    "'''\n",
    "\n",
    "# Setting the prompt template to create the generic summarization\n",
    "generic_summarization_template = ChatPromptTemplate(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = GENERIC_SUMMARIZATION_PROMPT)\n",
    "])\n",
    "\n",
    "# Creating the generic summarization simulation chain\n",
    "generic_summarization_chain = generic_summarization_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the simulated data file exists\n",
    "if not os.path.exists('simulated_data.csv'):\n",
    "\n",
    "    # Adding a new column 'summarized_text' by invoking the generic_summarization_chain on each row of 'original_text'\n",
    "    df['summarized_text'] = df['original_text'].apply(lambda text: generic_summarization_chain.invoke(input = {'original_text': text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the simulated data file exists\n",
    "if not os.path.exists('simulated_data.csv'):\n",
    "    \n",
    "    # Saving the DataFrame to a CSV file\n",
    "    df.to_csv('simulated_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
